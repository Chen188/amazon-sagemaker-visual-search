{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 可视图片搜索\n",
    "_**使用卷积神经网络和 Elasticsearch K-最近邻(KNN)索引检索视觉上相似的图像**_\n",
    "\n",
    "\n",
    "## 目录\n",
    "\n",
    "\n",
    "1. [背景](#Background)\n",
    "1. [下载Zalando Research数据](#Setup)\n",
    "1. [准备 TensorFlow 模型](#TensorFlow-Model-Preparation)\n",
    "1. [使用 SageMaker 托管模型](#Hosting-Model)\n",
    "1. [在 Elasticsearch 中创建一个 KNN 索引](#ES-KNN)\n",
    "1. [搜索结果评估](#Searching-with-ES-k-NN)\n",
    "1. [部署全栈视觉搜索应用程序](#)\n",
    "1. [拓展](#Extensions)\n",
    "\n",
    "## 背景\n",
    "\n",
    "在本笔记本中，我们将构建视觉图像搜索应用程序的核心组件。使用可视图像搜索，您可以查找与您所提供照片相似的照片，而无需通过语音或文本来查找这些内容。\n",
    "\n",
    "视觉图像搜索的核心组件之一是卷积神经网络（CNN）模型，该模型生成代表查询图像和要与查询进行比较的参考项目图像的“特征向量”。参考项目特征向量通常是离线生成的，必须存储在某种数据库中，以便可以对其进行有效搜索。对于小型参考项目数据集，可以使用蛮力搜索将查询与每个参考项目进行比较。但是，蛮力搜索大型数据集极其缓慢且不可行的。\n",
    "\n",
    "为了能够有效搜索视觉上相似的图像，我们将使用Amazon SageMaker从图像生成“特征向量”，并在Amazon Elasticsearch Service中使用KNN算法。 Amazon Elasticsearch Service的KNN使您可以在向量空间中搜索点，并通过欧几里得距离或余弦相似度（默认值为欧几里得距离）找到这些点的“最近邻居”。用例包括建议（例如，音乐应用程序中的“您可能喜欢的其他歌曲”功能），图像识别和欺诈检测。\n",
    "\n",
    "我们将按照以下步骤构建可视图像搜索：进行一些初始设置后，我们将使用TensorFlow准备模型以生成特征向量，然后从*__feidegger__*(一种*__zalandoresearch__*数据集)生成Fashion Images的特征向量。这些特征向量将导入到Amazon Elasticsearch KNN 索引中。接下来，我们将用一些图片测试下图像查询功能，并将结果可视化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install tqdm to have progress bar\n",
    "!pip install tqdm\n",
    "\n",
    "#install necessary pkg to make connection with elasticsearch domain\n",
    "!pip install elasticsearch\n",
    "!pip install requests\n",
    "!pip install requests-aws4auth\n",
    "\n",
    "# Use SageMaker version 1.72.1\n",
    "!pip install sagemaker==1.72.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import re\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "s3_resource = boto3.resource(\"s3\")\n",
    "s3 = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfn = boto3.client('cloudformation')\n",
    "\n",
    "def get_cfn_outputs(stackname):\n",
    "    outputs = {}\n",
    "    for output in cfn.describe_stacks(StackName=stackname)['Stacks'][0]['Outputs']:\n",
    "        outputs[output['OutputKey']] = output['OutputValue']\n",
    "    return outputs\n",
    "\n",
    "## Setup variables to use for the rest of the demo\n",
    "cloudformation_stack_name = \"vis-search\"\n",
    "\n",
    "outputs = get_cfn_outputs(cloudformation_stack_name)\n",
    "\n",
    "bucket = outputs['s3BucketTraining']\n",
    "es_host = outputs['esHostName']\n",
    "\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下载Zalando Research数据\n",
    "\n",
    "该数据集包含8732幅高分辨率图像，每幅图像均是Zalando商店中的衣服，图片都是白底的。\n",
    "\n",
    "**下载Zalando Research数据**：原始数据来自：https://github.com/zalandoresearch/feidegger\n",
    "\n",
    " **Citation:** <br>\n",
    " *@inproceedings{lefakis2018feidegger,* <br>\n",
    " *title={FEIDEGGER: A Multi-modal Corpus of Fashion Images and Descriptions in German},* <br>\n",
    " *author={Lefakis, Leonidas and Akbik, Alan and Vollgraf, Roland},* <br>\n",
    " *booktitle = {{LREC} 2018, 11th Language Resources and Evaluation Conference},* <br>\n",
    " *year      = {2018}* <br>\n",
    " *}*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Data Preparation\n",
    "use_small_data=True\n",
    "\n",
    "images_path = 'data/feidegger/fashion'\n",
    "\n",
    "if(use_small_data):\n",
    "    !wget https://us-east-1-binc.s3.amazonaws.com/ai-day-2021/visual-search/image_data_2k.tgz\n",
    "    !tar -xf image_data_2k.tgz\n",
    "else:\n",
    "    !wget https://us-east-1-binc.s3.amazonaws.com/ai-day-2021/visual-search/image_data.tgz\n",
    "    !tar -xf image_data.tgz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uploading dataset to S3\n",
    "\n",
    "!aws s3 sync data s3://$bucket/data/ --quiet && echo upload to $bucket/data finished"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备TensorFlow模型\n",
    "\n",
    "我们将使用TensorFlow后端准备一个模型，以将图像“特征化”为特征向量。 TensorFlow具有底层 Module API和高级Keras API。\n",
    "\n",
    "我们将从预先训练的模型开始，避免花费时间和金钱从头开始训练模型。 因此，作为准备模型的第一步，我们将从Keras应用程序中导入预训练的模型。 研究人员已经对具有不同层数的各种经过预训练的CNN架构进行了试验，发现有几种好的选择。\n",
    "\n",
    "在本笔记本中，我们将基于ResNet架构选择模型，这是一种常用的选择。 在层数的各种选择中，从18到152，我们将使用50层。 这也是一个常见的选择，可以平衡结果特征向量（嵌入）的表现力和计算效率（层数越少意味着效率越高，但表现力越低）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "import sagemaker\n",
    "from PIL import Image\n",
    "from sagemaker.tensorflow import TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the channel first for better performance\n",
    "from tensorflow.keras import backend\n",
    "backend.set_image_data_format('channels_first')\n",
    "print(backend.image_data_format())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，我们将导入一个ResNet50模型，该模型在Imagenet数据集上经过训练，可以在没有实际clssifier的情况下提取特征。更具体地说，我们将使用该层来生成浮点数的行向量，以作为“嵌入”或图像特征的表示。 我们还将模型另存为**export/Servo/1**下的*SavedModel*格式，以通过SageMaker TensorFlow服务API进行服务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Resnet50 model\n",
    "model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False,input_shape=(3, 224, 224),pooling='avg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the directory strcture\n",
    "dirName = 'export/Servo/1'\n",
    "if not os.path.exists(dirName):\n",
    "    os.makedirs(dirName)\n",
    "    print(\"Directory \" , dirName ,  \" Created \")\n",
    "else:    \n",
    "    print(\"Directory \" , dirName ,  \" already exists\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model in SavedModel format\n",
    "model.save('./export/Servo/1/', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the model Signature\n",
    "!saved_model_cli show --dir ./export/Servo/1/ --tag_set serve --signature_def serving_default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用 SageMaker 托管模型\n",
    "\n",
    "在保存特征提取器模型后，我们将使用Sagemaker Tensorflow Serving api部署模型。Sagemaker Tensorflow Serving是用于生产环境的机器学习模型托管系统，具有灵活，高性能的特性。 使用TensorFlow Serving可以轻松部署新算法和实验，同时保持相同的服务器体系结构和API。TensorFlow Serving提供与TensorFlow模型的现成集成，但可以轻松扩展以服务于其他类型的模型和数据。我们将定义**inference.py**来自定义TensorFlow Serving API的输入数据。 我们还需要添加**requirements.txt**到此容器中，以使用额外的库。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the actual content of inference.py\n",
    "!pygmentize src/inference.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "#zip the model .gz format\n",
    "model_version = '1'\n",
    "export_dir = 'export/Servo/' + model_version\n",
    "with tarfile.open('model.tar.gz', mode='w:gz') as archive:\n",
    "    archive.add('export', recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upload the model to S3\n",
    "sagemaker_session = sagemaker.Session()\n",
    "inputs = sagemaker_session.upload_data(path='model.tar.gz', key_prefix='model')\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将模型上传到S3之后，我们将使用TensorFlow Serving容器托管模型。 我们会使用ml.p3.16xlarge实例类型。您可能需要开一个support case以增加SageMaker托管实例类型的服务配额。 我们将使用此端点生成特征并将其导入ElasticSearch。 您还可以选择小型实例，例如“ ml.m4.xlarge”以节省成本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deploy the model in Sagemaker Endpoint. This process will take ~10 min.\n",
    "from sagemaker.tensorflow.serving import Model\n",
    "\n",
    "sagemaker_model = Model(entry_point='inference.py', model_data = 's3://' + sagemaker_session.default_bucket() + '/model/model.tar.gz',\n",
    "                                  role = role, framework_version='2.1.0', source_dir='./src' )\n",
    "\n",
    "predictor = sagemaker_model.deploy(initial_instance_count=3, instance_type='ml.c5.xlarge')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get the features for a sample image\n",
    "payload = s3.get_object(Bucket=bucket,Key='data/feidegger/fashion/0VB21C000-A11@12.1.jpg')['Body'].read()\n",
    "predictor.content_type = 'application/x-image'\n",
    "predictor.serializer   = None\n",
    "features = predictor.predict(payload)['predictions'][0]\n",
    "\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 在 Elasticsearch 中创建一个 KNN 索引\n",
    "\n",
    "Amazon Elasticsearch Service的KNN使您可以在向量空间中搜索点，并通过欧几里得距离或余弦相似度（默认值为欧几里得距离）找到这些点的“最近邻居”。 用例包括建议（例如，音乐应用程序中的“您可能喜欢的其他歌曲”功能），图像识别和欺诈检测。\n",
    "\n",
    "KNN需要Elasticsearch 7.1或更高版本。 OpenDistro for Elasticsearch文档中提供了有关Elasticsearch功能的完整文档，包括设置和统计信息的描述。 有关k最近邻算法的背景信息\n",
    "\n",
    "在这一步中，我们将获取zalando图像的所有特征，并将这些特征导入到Elastichseach7.4域中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define some utility function\n",
    "\n",
    "#return all s3 keys\n",
    "def get_all_s3_keys(bucket):\n",
    "    \"\"\"Get a list of all keys in an S3 bucket.\"\"\"    \n",
    "    keys = []\n",
    "\n",
    "    kwargs = {'Bucket': bucket}\n",
    "    while True:\n",
    "        resp = s3.list_objects_v2(**kwargs)\n",
    "        for obj in resp['Contents']:\n",
    "            keys.append('s3://' + bucket + '/' + obj['Key'])\n",
    "\n",
    "        try:\n",
    "            kwargs['ContinuationToken'] = resp['NextContinuationToken']\n",
    "        except KeyError:\n",
    "            break\n",
    "\n",
    "    return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the zalando images keys from the bucket make a list\n",
    "s3_uris = get_all_s3_keys(bucket)\n",
    "len(s3_uris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to extract image features\n",
    "from time import sleep\n",
    "\n",
    "sm_client = boto3.client('sagemaker-runtime')\n",
    "ENDPOINT_NAME = predictor.endpoint\n",
    "\n",
    "def get_predictions(payload):\n",
    "    return sm_client.invoke_endpoint(EndpointName=ENDPOINT_NAME,\n",
    "                                           ContentType='application/x-image',\n",
    "                                           Body=payload)\n",
    "\n",
    "def extract_features(s3_uri):\n",
    "    key = s3_uri.replace(f's3://{bucket}/', '')\n",
    "    payload = s3.get_object(Bucket=bucket,Key=key)['Body'].read()\n",
    "    try:\n",
    "        response = get_predictions(payload)\n",
    "    except:\n",
    "        sleep(0.1)\n",
    "        response = get_predictions(payload)\n",
    "\n",
    "    del payload\n",
    "    response_body = json.loads((response['Body'].read()))\n",
    "    feature_lst = response_body['predictions'][0]\n",
    "    \n",
    "    return s3_uri, feature_lst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This process cell will take approximately 24-25 minutes on a t3.medium notebook instance\n",
    "# with 3 m5.xlarge SageMaker Hosted Endpoint instances\n",
    "from multiprocessing import cpu_count\n",
    "from tqdm.contrib.concurrent import process_map\n",
    "\n",
    "workers = 4 * cpu_count()\n",
    "result = process_map(extract_features, s3_uris, max_workers=workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the Elasticsearch connection\n",
    "from elasticsearch import Elasticsearch, RequestsHttpConnection\n",
    "from requests_aws4auth import AWS4Auth\n",
    "region = 'us-east-1' # e.g. us-east-1\n",
    "service = 'es'\n",
    "credentials = boto3.Session().get_credentials()\n",
    "awsauth = AWS4Auth(credentials.access_key, credentials.secret_key, region, service, session_token=credentials.token)\n",
    "\n",
    "es = Elasticsearch(\n",
    "    hosts = [{'host': es_host, 'port': 443}],\n",
    "    http_auth = awsauth,\n",
    "    use_ssl = True,\n",
    "    verify_certs = True,\n",
    "    connection_class = RequestsHttpConnection\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define KNN Elasticsearch index maping\n",
    "knn_index = {\n",
    "    \"settings\": {\n",
    "        \"index.knn\": True\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"zalando_img_vector\": {\n",
    "                \"type\": \"knn_vector\",\n",
    "                \"dimension\": 2048\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the Elasticsearch index\n",
    "es.indices.create(index=\"idx_zalando\",body=knn_index,ignore=400)\n",
    "es.indices.get(index=\"idx_zalando\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# defining a function to import the feature vectors corrosponds to each S3 URI into Elasticsearch KNN index\n",
    "# This process will take around ~3 min.\n",
    "\n",
    "\n",
    "def es_import(i):\n",
    "    es.index(index='idx_zalando',\n",
    "             body={\"zalando_img_vector\": i[1], \n",
    "                   \"image\": i[0]}\n",
    "            )\n",
    "    \n",
    "process_map(es_import, result, max_workers=workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 搜索结果评估\n",
    "\n",
    "在这一步中，我们将使用SageMaker SDK和Boto3 SDK查询Elasticsearch以检索最近的邻居。 值得一提的是**zalando**数据集与Imagenet数据集非常相似。 现在，如果您遇到一个领域特定的问题，那么您需要在预先训练的特征提取器模型（例如VGG，Resnet，Xeception，Mobilenet等）之上训练该数据集，并创建一个新的特征提取器模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define display_image function\n",
    "def display_image(bucket, key):\n",
    "    response = s3.get_object(Bucket=bucket,Key=key)['Body']\n",
    "    img = Image.open(response)\n",
    "    return display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import random\n",
    "from PIL import Image\n",
    "import io\n",
    "urls = []\n",
    "# yellow pattern dess\n",
    "urls.append('https://fastly.hautelookcdn.com/products/D7242MNR/large/13494318.jpg')\n",
    "# T shirt kind dress\n",
    "urls.append('https://fastly.hautelookcdn.com/products/M2241/large/15658772.jpg')\n",
    "#Dotted pattern dress\n",
    "urls.append('https://fastly.hautelookcdn.com/products/19463M/large/14537545.jpg')\n",
    "\n",
    "img_bytes = requests.get(random.choice(urls)).content\n",
    "query_img = Image.open(io.BytesIO(img_bytes))\n",
    "query_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### SageMaker SDK 方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SageMaker SDK approach\n",
    "predictor.content_type = 'application/x-image'\n",
    "predictor.serializer   = None\n",
    "features = predictor.predict(img_bytes)['predictions'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "k = 5\n",
    "idx_name = 'idx_zalando'\n",
    "res = es.search(request_timeout=30, index=idx_name,\n",
    "                body={'size': k, \n",
    "                      'query': {'knn': {'zalando_img_vector': {'vector': features, 'k': k}}}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(k):\n",
    "    key = res['hits']['hits'][i]['_source']['image']\n",
    "    key = key.replace(f's3://{bucket}/','')\n",
    "    img = display_image(bucket,key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Boto3 方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client('sagemaker-runtime')\n",
    "ENDPOINT_NAME = predictor.endpoint # our endpoint name\n",
    "response = client.invoke_endpoint(EndpointName=ENDPOINT_NAME,\n",
    "                                       ContentType='application/x-image',\n",
    "                                       Body=img_bytes)\n",
    "\n",
    "response_body = json.loads((response['Body'].read()))\n",
    "features = response_body['predictions'][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "k = 5\n",
    "idx_name = 'idx_zalando'\n",
    "res = es.search(request_timeout=30, index=idx_name,\n",
    "                body={'size': k, \n",
    "                      'query': {'knn': {'zalando_img_vector': {'vector': features, 'k': k}}}})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(k):\n",
    "    key = res['hits']['hits'][i]['_source']['image']\n",
    "    key = key.replace(f's3://{bucket}/','')\n",
    "    img = display_image (bucket,key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 部署一个全栈视觉搜索应用程序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_resource.Object(bucket, 'backend/template.yaml').upload_file('./backend/template.yaml', ExtraArgs={'ACL':'public-read'})\n",
    "\n",
    "\n",
    "sam_template_url = f'https://{bucket}.s3.amazonaws.com/backend/template.yaml'\n",
    "\n",
    "# Generate the CloudFormation Quick Create Link\n",
    "\n",
    "print(\"单击下面的URL,以创建用于视觉搜索的后端API:\\n\")\n",
    "print((\n",
    "    'https://console.aws.amazon.com/cloudformation/home?region=us-east-1#/stacks/create/review'\n",
    "    f'?templateURL={sam_template_url}'\n",
    "    '&stackName=vis-search-api'\n",
    "    f'&param_BucketName={outputs[\"s3BucketTraining\"]}'\n",
    "    f'&param_DomainName={outputs[\"esDomainName\"]}'\n",
    "    f'&param_ElasticSearchURL={outputs[\"esHostName\"]}'\n",
    "    f'&param_SagemakerEndpoint={predictor.endpoint}'\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "既然您具有一个可正常工作的Amazon SageMaker终端节点来提取图像特征并在Elasticsearch上创建了KNN索引，您就可以构建一个现实世界的，全栈，且有ML能力的Web应用程序了。 您刚刚创建的SAM模板将部署Amazon API Gateway和AWS Lambda函数。 Lambda函数运行您的代码以响应发送到API网关的HTTP请求。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review the content of the Lambda function code.\n",
    "!pygmentize backend/lambda/app.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一旦CloudFormation堆栈显示CREATE_COMPLETE，请继续下面的单元格："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the REST endpoint for the search API to a config file, to be used by the frontend build\n",
    "\n",
    "import json\n",
    "api_endpoint = get_cfn_outputs('vis-search-api')['ImageSimilarityApi']\n",
    "\n",
    "with open('./frontend/src/config/config.json', 'w') as outfile:\n",
    "    json.dump({'apiEndpoint': api_endpoint}, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 步骤 2: 部署前端服务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add NPM to the path so we can assemble the web frontend from our notebook code\n",
    "\n",
    "from os import environ\n",
    "\n",
    "npm_path = ':/home/ec2-user/anaconda3/envs/JupyterSystemEnv/bin'\n",
    "\n",
    "if npm_path not in environ['PATH']:\n",
    "    ADD_NPM_PATH = environ['PATH']\n",
    "    ADD_NPM_PATH = ADD_NPM_PATH + npm_path\n",
    "else:\n",
    "    ADD_NPM_PATH = environ['PATH']\n",
    "    \n",
    "%set_env PATH=$ADD_NPM_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ./frontend/\n",
    "\n",
    "!npm install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!npm run-script build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hosting_bucket = f\"s3://{outputs['s3BucketHostingBucketName']}\"\n",
    "\n",
    "!aws s3 sync ./build/ $hosting_bucket --acl public-read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 步骤 3: 浏览您的前端服务，并上传图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('点击下面的URL:\\n')\n",
    "print(outputs['S3BucketSecureURL'] + '/index.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "您应该看到以下页面：\n",
    "\n",
    "![Website](pi3small.png)\n",
    "\n",
    "在网站上，尝试将以下URL粘贴在URL文本字段中。\n",
    "\n",
    "`https://i4.ztat.net/large/VE/12/1C/14/8K/12/VE121C148-K12@10.jpg`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 拓展\n",
    "\n",
    "我们使用了在Imagenet数据集上进行训练的预训练Resnet50模型。 现在，根据您的用例，您可以使用自己的数据集微调任何预先训练的模型，例如VGG，Inception和MobileNet，并将模型托管在Amazon SageMaker中。\n",
    "\n",
    "您还可以使用Amazon SageMaker Batch转换作业从存储的S3图像中提取大量特征，然后可以使用AWS Glue将该数据导入Elasticeearch域。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 清理资源\n",
    "\n",
    "确保您停止笔记本实例，删除Amazon SageMaker终端节点并删除Elasticsearch域，以防止产生任何额外费用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the endpoint\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty S3 Contents\n",
    "training_bucket_resource = s3_resource.Bucket(bucket)\n",
    "training_bucket_resource.objects.all().delete()\n",
    "\n",
    "hosting_bucket_resource = s3_resource.Bucket(outputs['s3BucketHostingBucketName'])\n",
    "hosting_bucket_resource.objects.all().delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}